---
title: "TMI - Homework L7"
author:
- Alfonzetti Giuseppe,
- Castiglione Cristian,
- Iadevito Alessandro,
- Pozza Francesco
header-includes: \usepackage{amsmath}
output:
  pdf_document:
    number_sections: no
    toc: no
  html_document:
    df_print: paged
    toc: no
fontsize: 12pt
---

# Exercise 1:
Let weib.y be an i.i.d. sample from a gamma r.v.
```{r echo=FALSE, include=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=6, fig.align="center") 
library(tidyverse)
library(ggpubr)
weib.y = c(225, 171, 198, 189, 189, 135, 162, 135, 117, 162)
```

with density
$$\frac{1}{\Gamma(\theta)}3^\theta y^{\theta-1}e^{-3y}\quad y,\theta>0$$

1. Find the m.l.e. of $\theta$ solving the likelihood equation and also maximizing directly the log likelihood.
2. Plot the relative log likelihood and find the 0.90 Wald and deviance confidence intervals.
3. Repeat the previous points considering the parameterization $\omega=\log\theta$.
4. Assume a prior $N(0,\sigma_0^2)$ for $\omega$ and perform a Bayesian analysis of the data, using both analytical and
simulation-based solutions.

## Solution :
We have $Y\sim Ga(\theta,3)$, with $\theta\in\Theta$ then
\begin{eqnarray*}
  \mathcal{L}^\Theta (\theta;y) &=& \mathcal{L}(\theta;y) \propto \frac{1}{\Gamma(\theta)^n}3^{n\theta}\prod_{i=1}^ny_i^{\theta-1}\\
  l^\Theta (\theta;y) &=& \mathcal{l}(\theta;y) = -n\log\Gamma(\theta) + n\theta\log 3 + (\theta-1)\sum_{i=1}^{n}\log y_i \\
  &=& -n\log\Gamma(\theta) + n\theta\log 3 + (\theta-1)t_1\\
  \textit{with}\; t_1&=& \sum_{i=1}^{n}\log y_i
\end{eqnarray*}
Therefore 
\begin{eqnarray*}
  l_*(\theta;y) &=& -n\psi(\theta) + n\log 3 + t_1 = 0\\
  l_{(2)}(\theta;y) &=& n\frac{\Gamma'(\theta)-\Gamma''(\theta)\Gamma(\theta)}{\Gamma(\theta)^2}
\end{eqnarray*}
\newpage 
Let's start defining the appropriate functions
```{r}
t1 = function(data){ #sufficient statistic
  t = sum( log(data) )
  return(t)
}
nllik = function(th, data){ #log likelihood
  n = length(data)
  t = t1(data)
  l = -n*lgamma(th)+n*th*log(3)+(th-1)*t
  return(-l)
}
score = function(th, data){ #score function
  n = length(data)
  t = t1(data)
  s = -n*digamma(th)+n*log(3) + t
  return(s)
}
```

We can now find the m.l.e. solving the likelihood function
```{r}
mle_score = nleqslv::nleqslv(0.5, score, data = weib.y, jacobian = TRUE)

print(c(mle_score$x, mle_score$jac))
```

or maximizing directly the log-likelihood
```{r }
mle_llik = optim(400, fn = nllik, method = 'L-BFGS-B', 
                 lower = 0, upper = 1000, hessian = T, data = weib.y)

thhat = mle_llik$par #mle
llik_thhat = -mle_llik$value #maximum loglikelihood
j_thhat = mle_llik$hessian #observed info in the maximum
print(c(thhat, j_thhat))
```

We can now compute Wald and deviance confidence intervals for a given confidence level $1-\alpha =0.9$
```{r}
#### wald confidence interval theta ####
conf = .9
th_wald_ci = c(
  thhat - qnorm(1 - (1 - conf)/2) *1/sqrt(j_thhat),
  thhat + qnorm(1 - (1 - conf)/2) *1/sqrt(j_thhat)
) 

#### deviance confidence interval theta ####
th_dev_ci = c(
  #left solution
  uniroot(function(x) -nllik(x, data = weib.y) - llik_thhat + qchisq(conf,1)/2, 
          c(480, thhat))$root,
  #right solution
  uniroot(function(x) -nllik(x, data = weib.y) - llik_thhat + qchisq(conf,1)/2, 
          c(thhat, 520))$root
)
```

and plot them over the relative loglikelihood $l(\theta)-l(\hat\theta)$
```{r echo=FALSE, warning=FALSE}
#### results for theta parameterization ####
th_tab_ci = data.frame(
  ci = c('wald', 'deviance'),
  lower = c(th_wald_ci[1], th_dev_ci[1]),
  upper = c(th_wald_ci[2], th_dev_ci[2])
) 

p = tibble(theta = seq(0,1000,1)) %>%
  mutate(rel_ll = -nllik(theta, data = weib.y) - llik_thhat) %>%
  ggplot(aes(x = theta, y = rel_ll))+
  geom_line(alpha =.8) +
  geom_hline(yintercept = -qchisq(conf,1)/2, linetype = 'dashed', alpha =.5) +
  scale_y_continuous(limits = c(-10,0),
                     breaks = round(c(-10,-7.5,-5,-2.5, -qchisq(conf,1)/2, 0),1),
                     labels = c(-10,-7.5,-5,-2.5, expression(frac( {chi^2}[{paste(1,',',1-alpha)}],2)) , 0) ) +
  geom_vline(xintercept = thhat, linetype = 'dashed', alpha = .5) +
  scale_x_continuous(limits = c(460,530), 
                     breaks = round(c(460, 480, thhat ,520,540),0),
                     labels = c('460', '480', expression(hat(theta)),'520','540')) +
  geom_vline(aes(col='wald', xintercept = th_wald_ci[[1]]), size =1, linetype = 'dashed', alpha = 1) +
  geom_vline(aes(col='wald', xintercept = th_wald_ci[[2]]), size =1, linetype = 'dashed', alpha = 1) +
  geom_vline(aes(col='deviance', xintercept = th_dev_ci[[1]]), linetype = 'dashed', alpha = 1) +
  geom_vline(aes(col='deviance', xintercept = th_dev_ci[[2]]), linetype = 'dashed', alpha = 1) +
  labs(y = 'relative log-likelihood', x = '', col = 'Confidence Interval:',
       caption = substitute(paste(hat(theta), '=', nn), list(nn=round(thhat,1))))+
  theme_minimal() +
  theme(legend.position = 'top')
ggarrange(ggtexttable(th_tab_ci, rows = NULL),p, nrow = 2, heights = c(.5, 1.5))
```

If we now step to the $\omega=\log\theta\in\Omega$ parameterization, we need to specify the functions for $\theta(\omega)=\exp(\omega)$ and, exploiting the equivarinace property of the likelihood, $l(\omega)=l^\Omega(\theta(\omega))$
```{r}
w_of = function(theta){log(theta)}# omega of theta (new parameterization)
th_of = function(w){exp(w)} # theta of omega (back to the original parameterization)
nllik_w = function(w, data){ # negative log likelihood as function of omega
  nllik(th = th_of(w), data = data)
}
```

so we can easly find $\hat\omega$ and plug-in it into the log-likelihood to get $l^\Omega(\hat\omega)$ 
```{r}
what = w_of(thhat) #equivariance
llik_what = -nllik_w(what, data = weib.y)#equivariance
```

Regarding the observed information $j^\Omega(\hat\omega)$ we can compute it numerically with
```{r}
j_what = optimHess(what, nllik_w, data = weib.y)
j_what
```

Given the reparameterized likelihood quantites we can compute the Wald and deviance confidence intrervals as done before
```{r}
#### wald confidence interval omega ####
conf = .9
w_wald_ci = c(
  what - qnorm(1 - (1 - conf)/2) *1/sqrt(j_what),
  what + qnorm(1 - (1 - conf)/2) *1/sqrt(j_what)
) 
#### deviance confidence interval omega ####
w_dev_ci = c(
  uniroot(function(x) -nllik_w(x, data = weib.y) - llik_what + qchisq(conf,1)/2, 
          c(6.175, what))$root,
  uniroot(function(x) -nllik_w(x, data = weib.y) - llik_what + qchisq(conf,1)/2, 
          c(what, 6.25))$root
  
) 
```

and plot them on the relative loglikelihood $l^\Omega(\omega)-l^\Omega(\hat\omega)$
```{r echo=FALSE, warning=FALSE}
w_tab_ci = data.frame(
  ci = c('wald', 'deviance'),
  lower = c(w_wald_ci[1], w_dev_ci[1]),
  upper = c(w_wald_ci[2], w_dev_ci[2])
) 

p = tibble(w = seq(5,7,0.001)) %>%
  mutate( rel_ll = -nllik(th=exp(w), data = weib.y) - llik_what) %>%
  ggplot(aes(x = w, y = rel_ll))+
  geom_line(alpha =.8)+
  geom_vline(xintercept = what, linetype = 'dashed', alpha =.5) +
  geom_hline(yintercept = -qchisq(conf,1)/2, linetype = 'dashed', alpha =.5) +
  scale_y_continuous(limits = c(-5,0),
                     breaks = round(c(-5, -3, -qchisq(conf,1)/2, 0),1),
                     labels = c(-5,-3,expression(frac( {chi^2}[{paste(1,',',1-alpha)}],2)) , 0) ) +
  scale_x_continuous(limits = c(6.15,6.25), 
                     breaks = round(c(6.15, what ,6.25),2),
                     labels = c('6.15', expression(hat(omega)),'6.25')) +
  geom_vline(aes(col='wald', xintercept = w_wald_ci[[1]]), size =1, linetype = 'dashed', alpha = 1) +
  geom_vline(aes(col='wald', xintercept = w_wald_ci[[2]]), size =1, linetype = 'dashed', alpha = 1) +
  geom_vline(aes(col='deviance', xintercept = w_dev_ci[[1]]), linetype = 'dashed', alpha = 1) +
  geom_vline(aes(col='deviance', xintercept = w_dev_ci[[2]]), linetype = 'dashed', alpha = 1) +
  labs(y = 'relative log-likelihood', x = '', col = 'Confidence Interval:', 
       caption = substitute(paste(hat(omega), '=', nn), list(nn=round(what,3))))+
  theme_minimal() +
  theme(legend.position = 'top')
ggarrange(ggtexttable(w_tab_ci, rows = NULL),p, nrow = 2, heights = c(.5, 1.5))
```


# Exercise 2:
Consider the following data
```{r}
data = c(1.434313, 1.122792, 1.205189, 0.08399036, 2.700203, 1.621289,
0.5877176, 1.337052, 4.893989, 2.386678, 2.631867, 0.2630924,
3.077384, 2.815827, 0.3646507)
```

as an i.i.d. sample from a gamma r.v. with shape $\alpha$ and scale $1/\beta$.

1. Find the m.l.e. and plot the relative log likelihood.
2. Repeat the previous point with the parameterization $(\alpha, \mu) = (\alpha, \alpha/\beta)$. Comment on the results.

## Solution:

\newpage
# Exercise 3:
Consider Exercise 7 pag. 158 of Davison (2003). Consider the model described in the exercise, with $Y_i$ , the i-th claim, distributed as an exponential with mean $\mu_i$ and with $\log \mu_i = \beta_0 + \beta_1 x_i$, where $x_i$ is equal to $0$ for claims of hospital A and $1$ for claims of hospital B.

1. Write the log likelihood for $(\beta_0 ,\beta_1)$ and make a contour plot.
2. Obtain numerically the maximum likelihood estimate and estimates of the standard errors for each component.
3. Write a function that computes the profile log likelihood for $\beta_1$ and plot it in a sensible range of parameter
values.
4. Compute a $0.95$ deviance confidence interval for $\beta_1$ and compare it with the corresponding Wald interval.
5. Use the profile log likelihood for $\beta_1$ to provide a p-value for the null hypothesis that the two hospitals have the
same expected claim value.
6. Perform a Bayesian analysis for $(\beta_0 ,\beta_1)$ assuming for the parameters independent normal priors with mean $0$
and standard deviation $10$.

## Solution:






